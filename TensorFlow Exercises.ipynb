{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npython --version\\nconda create -n tensorflow python=2.7\\nsource activate tensorflow\\ncd ..\\nmkdir tf\\ncd tf\\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0-py2-none-any.whl\\nconda install -c conda-forge tensorflow\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Basics and installation: http://www.jorditorres.org/first-contact-with-tensorflow/\n",
    "# Useful example to print and run:  http://katbailey.github.io/post/matrix-factorization-with-tensorflow/\n",
    "\n",
    "# Other way to install: \n",
    "'''\n",
    "python --version\n",
    "conda create -n tensorflow python=2.7\n",
    "source activate tensorflow\n",
    "cd ..\n",
    "mkdir tf\n",
    "cd tf\n",
    "export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0-py2-none-any.whl\n",
    "conda install -c conda-forge tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic values and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62619925"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_scalar = tf.random_uniform(())\n",
    "sess = tf.Session()\n",
    "sess.run(random_scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both TensorFlow and NumPy allow nearly any variable to take the form of a tensor (i.e., a vector, a matrice, or a higher-order such structure). We can do random uniform within a range and put this in float or integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 5],\n",
       "       [1, 1, 8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = tf.random_uniform((2,3),minval=0, maxval=10,dtype=tf.int64)\n",
    "sess = tf.Session()\n",
    "sess.run(random_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a function, it should return a tensor. And we should call it by a session with feedback: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  4.  6.]\n"
     ]
    }
   ],
   "source": [
    "def tf_fn(x):\n",
    "    return tf.mul(x,2)\n",
    "\n",
    "x = tf.placeholder(\"float\", 4)\n",
    "func = tf_fn(x)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    result = session.run(func, feed_dict={x:  np.array([0, 1, 2, 3])})\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(\"float\")\n",
    "b = tf.placeholder(\"float\")\n",
    "y = tf.mul(a, b)\n",
    "\n",
    "sess = tf.Session()\n",
    "print  sess.run(y, feed_dict={a: 3, b: 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [5 3]]\n",
      "[[9 4]\n",
      " [7 6]]\n",
      "mul result (one by one):  [18 53] \n",
      "\n",
      "dot product or matrix mult with matmul result (matrix):  [[18  8]\n",
      " [66 38]] \n",
      "\n",
      "[[2]\n",
      " [3]]\n",
      "[[1 1 2]\n",
      " [1 2 3]]\n",
      "mul result with defined vector:  [[2 2 4]\n",
      " [3 6 9]] \n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### Variables with vectors\n",
    "dim1 = 2   # columns = rank = features\n",
    "dim2 = 2   # rows = observations\n",
    "M1 = tf.Variable(tf.random_uniform([dim1,dim2],minval=0, maxval=10,dtype=tf.int32))\n",
    "M2 = tf.Variable(tf.random_uniform([dim2,dim1],minval=0, maxval=10,dtype=tf.int32)) \n",
    "\n",
    "L1 = tf.Variable( [ [2],[3] ] )               # Two and three times the vector\n",
    "#L1 = tf.Variable( [ [2] ] )                   # Two times the vector\n",
    "L2 = tf.Variable( [[1,1,2],[1,2,3]] )         # This is the vector\n",
    "\n",
    "c = tf.constant(1.0)\n",
    "\n",
    "##### Operations\n",
    "M = tf.reduce_sum( tf.mul(M1,M2), 1)\n",
    "M_M = tf.matmul(M1,tf.reshape(M2,[dim2,dim1]))\n",
    "L = tf.mul(L1,L2)\n",
    "\n",
    "##### Tensorflow Session\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "##### Print results\n",
    "\n",
    "results = sess.run([M1,M2,M,M_M])\n",
    "print results[0]\n",
    "print results[1]\n",
    "print \"mul result (one by one): \", results[2], \"\\n\"\n",
    "print \"dot product or matrix mult with matmul result (matrix): \", results[3], \"\\n\"\n",
    "\n",
    "results = sess.run([L1,L2,L])\n",
    "print results[0]\n",
    "print results[1]\n",
    "print \"mul result with defined vector: \", results[2], \"\\n\"\n",
    "\n",
    "print sess.run(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for values in a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " [2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 5.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0],\n",
       " [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = [[ 0. ,2. ,1. ,1. ,1., 1. , 1.], [ 2. , 0. , 0., 3. , 1.,  1. , 5.], [ 0. , 0. , 0.,  1. , 1.,  1. , 0.],\n",
    "          [ 1. , 1.,  1.,  0.,  1.,  1.,  0.], [ 1. , 0. , 1. , 1. , 0. , 1. , 0.], \n",
    "          [ 1.,  1.,  1.,  1.,  1.,  0.,  0.], [ 1. , 1.,  0.,  0.,  0. , 0. , 0.]]\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 3), (1, 6), (3, 0), (5, 4)}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_index = set([(1, 3), (3, 0), (5, 4), (1, 6),(1,4),(0,1)])\n",
    "index_to_look = set([(1, 3), (3, 0), (5, 4), (1, 6)])\n",
    "index_to_look "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  3.  5.]\n",
      "[[3 0]\n",
      " [5 4]\n",
      " [1 3]\n",
      " [1 6]]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### Variables in tensorflow\n",
    "params = tf.Variable( matrix )        \n",
    "ids = tf.Variable( list(index_to_look)  ) \n",
    "\n",
    "ids_position1 = tf.gather_nd(ids,tf.ones(len(ide)))\n",
    "\n",
    "vectors_selection = tf.gather_nd(params, ids)\n",
    "\n",
    "##### Tensorflow Session\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "##### Print results\n",
    "print sess.run( vectors_selection )\n",
    "print sess.run( ids )\n",
    "print sess.run( ids_position1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Vectors Algorithm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights i per word:  [[ 0.32101893  0.00588596  0.17248464]\n",
      " [ 0.48212528  0.82793736  0.8897953 ]\n",
      " [ 0.74746346  0.24163473  0.10198379]\n",
      " [ 0.42474997  0.06667519  0.28107142]]\n",
      "weights j per word:  [[ 0.32573187  0.16539848  0.74664092]\n",
      " [ 0.819417    0.76093197  0.51857352]\n",
      " [ 0.07197762  0.53984177  0.63790977]\n",
      " [ 0.93306565  0.4713881   0.99553132]]\n",
      "\n",
      "\n",
      "weights mult ij:  [[ 0.1045661   0.00097353  0.12878409]\n",
      " [ 0.39506164  0.63000399  0.46142429]\n",
      " [ 0.05380064  0.13044451  0.06505645]\n",
      " [ 0.3963196   0.03142989  0.27981541]]\n",
      "weights dot prod result ij:  [ 0.23432371  1.48649001  0.24930161  0.70756489]\n",
      "\n",
      "\n",
      "X input (coocurrences):  [ 0.          0.          1.09861231  1.60943794]\n",
      "W [[ 0.58161545  0.59163451  0.64252329]\n",
      " [ 0.50284922  0.88060546  0.45352566]\n",
      " [ 0.87048972  0.47148263  0.95153987]\n",
      " [ 0.3252964   0.5925988   0.83370912]\n",
      " [ 0.65519285  0.17015147  0.00559783]\n",
      " [ 0.27518439  0.9471159   0.17665291]]\n",
      "W [3, 5, 1, 1]\n",
      "W [[ 0.3252964   0.5925988   0.83370912]\n",
      " [ 0.27518439  0.9471159   0.17665291]\n",
      " [ 0.50284922  0.88060546  0.45352566]\n",
      " [ 0.50284922  0.88060546  0.45352566]]\n",
      "results fminimum:  [ 0.  0.  1.  1.]\n",
      "\n",
      "\n",
      "results costs:  [ 1.23432374  2.48649001  2.34791398  3.31700277]\n",
      "results sqr costs:  [  1.52355504   6.18263245   5.51270008  11.00250721]\n",
      "mean reduction for the minibatch:  2.34643\n",
      "NUMPY SELECTION EQUIVALENT TO TF.GATHER [3, 5, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### Variables in tensorflow\n",
    "params = tf.Variable( matrix )        \n",
    "ids = tf.Variable( list(index_to_look)  ) \n",
    "vectors_selection = tf.gather_nd(params, ids)\n",
    "\n",
    "dim1 = len(index_to_look)\n",
    "dim2 = 3\n",
    "M1 = tf.Variable(tf.random_uniform([dim1,dim2],minval=0, maxval=1,dtype=tf.float32))\n",
    "M2 = tf.Variable(tf.random_uniform([dim1,dim2],minval=0, maxval=1,dtype=tf.float32))\n",
    "M = tf.mul(M1,M2)\n",
    "M_r = tf.reduce_sum(M,1)\n",
    "b = tf.Variable(tf.ones([dim1]),dtype=tf.float32)  \n",
    "\n",
    "X = tf.log(vectors_selection)\n",
    "fmax = tf.minimum(X,tf.ones([dim1]))\n",
    "\n",
    "weights =  tf.Variable(tf.random_uniform([len(all_index),dim2],minval=0, maxval=1,dtype=tf.float32))\n",
    "wi = [i for (i,j) in index_to_look]  \n",
    "wj =  [j for (i,j) in index_to_look]  \n",
    "\n",
    "\n",
    "result = M_r + b + X\n",
    "result_sqr = result**2\n",
    "\n",
    "comparison = tf.ones(dim1)*5.\n",
    "quares = result_sqr < comparison\n",
    "        \n",
    "##### Tensorflow Session\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "\n",
    "print \"weights i per word: \",sess.run(M1)\n",
    "print \"weights j per word: \",sess.run(M2)\n",
    "\n",
    "print \"\\n\"\n",
    "print \"weights mult ij: \",sess.run(M)\n",
    "print \"weights dot prod result ij: \",sess.run(M_r)\n",
    "print \"\\n\"\n",
    "print \"X input (coocurrences): \",sess.run(X)\n",
    "print \"W\", sess.run(weights)\n",
    "print \"W\", wi\n",
    "print \"W\", sess.run(weights)[wi,:]\n",
    "print \"results fminimum: \",sess.run(fmax)\n",
    "print \"\\n\"\n",
    "print \"results costs: \",sess.run(result)\n",
    "print \"results sqr costs: \", sess.run(result_sqr)\n",
    "print \"mean reduction for the minibatch: \",sess.run(tf.reduce_mean(result))\n",
    "\n",
    "## numpy subselection of matrix by indices\n",
    "\n",
    "print \"NUMPY SELECTION EQUIVALENT TO TF.GATHER\", list(zip(*index_to_look)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PREMISE AND HYPOTHESIS EXAMPLE CONCATENATED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hp\n",
      "[[ 17.54130554  -8.90909195 -11.56913757]\n",
      " [ -6.45233631   6.53700829   1.03490829]\n",
      " [ 18.73347473  -2.52202034 -18.44117165]]\n",
      "Hh\n",
      "[[  9.42677498 -16.72008896   4.15140533]\n",
      " [-19.28181076  -9.3717289   -7.19891548]\n",
      " [ -2.93381119  -3.1003418   17.21966553]]\n",
      "Concatenated\n",
      "[[  17.54130554   -8.90909195  -11.56913757    9.42677498  -16.72008896\n",
      "     4.15140533    8.11453056    7.81099701  -15.72054291  165.35794067\n",
      "   148.96081543  -48.02817917]\n",
      " [  -6.45233631    6.53700829    1.03490829  -19.28181076   -9.3717289\n",
      "    -7.19891548   12.82947445   15.90873718    8.23382378  124.41272736\n",
      "   -61.26306915   -7.45021725]\n",
      " [  18.73347473   -2.52202034  -18.44117165   -2.93381119   -3.1003418\n",
      "    17.21966553   21.66728592    0.57832146  -35.66083527  -54.96047592\n",
      "     7.81912518 -317.55081177]]\n",
      "W\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "b\n",
      "[ 1.]\n",
      "logits\n",
      "[[ 261.41674805]\n",
      " [  58.93860626]\n",
      " [-368.15161133]]\n",
      "maxsoft\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "relu\n",
      "[[ 261.41674805]\n",
      " [  58.93860626]\n",
      " [   0.        ]]\n",
      "logitssrelu\n",
      "[[ 262.41674805]\n",
      " [  59.93860626]\n",
      " [   1.        ]]\n",
      "maxsoftrelu\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "dim1 = 3\n",
    "dim2 = 3\n",
    "\n",
    "M1 = tf.Variable(tf.random_uniform([dim1,dim2],minval=-20, maxval=20))\n",
    "M2 = tf.Variable(tf.random_uniform([dim2,dim1],minval=-20, maxval=20)) \n",
    "\n",
    "W_cl = tf.Variable(tf.ones([4*dim1, 1]))\n",
    "\n",
    "W_rel = tf.Variable(tf.ones([4*dim1, 1]))\n",
    "W_relcl = tf.Variable(tf.ones([1, 1]))\n",
    "\n",
    "b_cl = tf.Variable(tf.ones([1]))\n",
    "\n",
    "M = tf.concat(1,[M1,M2,M1-M2,M1*M2])\n",
    "\n",
    "logs = tf.matmul(M,W_cl)+ b_cl\n",
    "soft = tf.nn.softmax(logs)\n",
    "\n",
    "relu = tf.nn.relu(tf.matmul(M,W_rel)+ b_cl)\n",
    "logsrelu = tf.matmul(relu,W_relcl)+ b_cl\n",
    "softrelu = tf.nn.softmax(logsrelu)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "##### Print results\n",
    "\n",
    "results = sess.run([M1,M2,M,W_cl,b_cl,logs,soft,relu,logsrelu,softrelu])\n",
    "print \"Hp\\n\",results[0]\n",
    "print \"Hh\\n\",results[1]\n",
    "print \"Concatenated\\n\",results[2]\n",
    "print \"W\\n\",results[3].transpose()\n",
    "print \"b\\n\",results[4]\n",
    "print \"logits\\n\",results[5]\n",
    "print \"maxsoft\\n\",results[6]\n",
    "print \"relu\\n\",results[7]\n",
    "print \"logitssrelu\\n\",results[8]\n",
    "print \"maxsoftrelu\\n\",results[9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PREMISE AND HYPOTHESIS EXAMPLE CONCATENATED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hp\n",
      "[[ 17.54130554  -8.90909195 -11.56913757]\n",
      " [ -6.45233631   6.53700829   1.03490829]\n",
      " [ 18.73347473  -2.52202034 -18.44117165]]\n",
      "Hh\n",
      "[[  9.42677498 -16.72008896   4.15140533]\n",
      " [-19.28181076  -9.3717289   -7.19891548]\n",
      " [ -2.93381119  -3.1003418   17.21966553]]\n",
      "Concatenated\n",
      "[[  17.54130554   -8.90909195  -11.56913757    9.42677498  -16.72008896\n",
      "     4.15140533    8.11453056    7.81099701  -15.72054291  165.35794067\n",
      "   148.96081543  -48.02817917]\n",
      " [  -6.45233631    6.53700829    1.03490829  -19.28181076   -9.3717289\n",
      "    -7.19891548   12.82947445   15.90873718    8.23382378  124.41272736\n",
      "   -61.26306915   -7.45021725]\n",
      " [  18.73347473   -2.52202034  -18.44117165   -2.93381119   -3.1003418\n",
      "    17.21966553   21.66728592    0.57832146  -35.66083527  -54.96047592\n",
      "     7.81912518 -317.55081177]]\n",
      "W\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "b\n",
      "[ 1.]\n",
      "logits\n",
      "[[ 261.41674805]\n",
      " [  58.93860626]\n",
      " [-368.15161133]]\n",
      "maxsoft\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "relu\n",
      "[[ 261.41674805]\n",
      " [  58.93860626]\n",
      " [   0.        ]]\n",
      "logitssrelu\n",
      "[[ 262.41674805]\n",
      " [  59.93860626]\n",
      " [   1.        ]]\n",
      "maxsoftrelu\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "dim1 = 3\n",
    "dim2 = 3\n",
    "\n",
    "M1 = tf.Variable(tf.random_uniform([dim1,dim2],minval=-20, maxval=20))\n",
    "M2 = tf.Variable(tf.random_uniform([dim2,dim1],minval=-20, maxval=20)) \n",
    "\n",
    "W_cl = tf.Variable(tf.ones([4*dim1, 1]))\n",
    "\n",
    "W_rel = tf.Variable(tf.ones([4*dim1, 1]))\n",
    "W_relcl = tf.Variable(tf.ones([1, 1]))\n",
    "\n",
    "b_cl = tf.Variable(tf.ones([1]))\n",
    "\n",
    "M = tf.concat(1,[M1,M2,M1-M2,M1*M2])\n",
    "\n",
    "logs = tf.matmul(M,W_cl)+ b_cl\n",
    "soft = tf.nn.softmax(logs)\n",
    "\n",
    "relu = tf.nn.relu(tf.matmul(M,W_rel)+ b_cl)\n",
    "logsrelu = tf.matmul(relu,W_relcl)+ b_cl\n",
    "softrelu = tf.nn.softmax(logsrelu)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "\n",
    "##### Print results\n",
    "\n",
    "results = sess.run([M1,M2,M,W_cl,b_cl,logs,soft,relu,logsrelu,softrelu])\n",
    "print \"Hp\\n\",results[0]\n",
    "print \"Hh\\n\",results[1]\n",
    "print \"Concatenated\\n\",results[2]\n",
    "print \"W\\n\",results[3].transpose()\n",
    "print \"b\\n\",results[4]\n",
    "print \"logits\\n\",results[5]\n",
    "print \"maxsoft\\n\",results[6]\n",
    "print \"relu\\n\",results[7]\n",
    "print \"logitssrelu\\n\",results[8]\n",
    "print \"maxsoftrelu\\n\",results[9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pack_2lists_reshaped (6,)\n",
      "Hp\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "pack_tensor [ 0.5  0.5]\n",
      "pack_2lists [[ 0.5  1.   1. ]\n",
      " [ 0.5  1.   1. ]]\n",
      "pack_2lists_reshaped [ 0.5  1.   1.   0.5  1.   1. ]\n",
      "e  [[  9.99999975e-05   1.00000005e-03]\n",
      " [  5.00000000e-01   1.00000005e-03]\n",
      " [  3.00000014e-04   9.99999978e-03]]\n",
      "soft_e [ 0.30408338  0.39043128  0.3054854 ]\n",
      "reduce_soft_e 0.390431\n",
      "new [ 0.5  1.   1.   0.5  1.   1.   0.5  1.   1.   0.5  1.   1. ]\n",
      "pack_2lists_reshaped_back [[ 0.5  1.   1. ]\n",
      " [ 0.5  1.   1. ]]\n",
      "new back [[[ 0.5  1.   1. ]\n",
      "  [ 0.5  1.   1. ]]\n",
      "\n",
      " [[ 0.5  1.   1. ]\n",
      "  [ 0.5  1.   1. ]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "dim1 = 3\n",
    "W_cl = tf.Variable(tf.zeros([dim1, 1]))\n",
    "\n",
    "alpha = [0.5,0.5]\n",
    "pack_tensor = tf.pack(alpha)\n",
    "alpha = [[0.5,1,1],[0.5,1,1]]\n",
    "pack_2lists = tf.pack(alpha)\n",
    "pack_2lists_reshaped = tf.reshape( tf.pack(alpha), [-1] )\n",
    "print \"pack_2lists_reshaped\", pack_2lists_reshaped.get_shape()\n",
    "pack_2lists_reshaped_back = tf.reshape( tf.pack(alpha), [2,3] )\n",
    "\n",
    "e = [[0.0001,0.001],[0.5,0.001],[0.0003,0.01]]\n",
    "e = tf.pack(e)\n",
    "soft_e = tf.nn.softmax(tf.reduce_mean(e,1))\n",
    "reduce_soft_e = tf.reduce_max(soft_e)\n",
    "\n",
    "new = tf.concat( 0, [pack_2lists_reshaped,pack_2lists_reshaped] )\n",
    "new_back = tf.reshape( new , [2,2,3] )\n",
    "\n",
    "### Session\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "##### Results\n",
    "results = sess.run( [W_cl, pack_tensor, pack_2lists,pack_2lists_reshaped, e, soft_e, reduce_soft_e, new,\n",
    "                    pack_2lists_reshaped_back, new_back] , )\n",
    "\n",
    "print \"Hp\\n\",results[0]\n",
    "print \"pack_tensor\", results[1]\n",
    "print \"pack_2lists\", results[2]\n",
    "print \"pack_2lists_reshaped\", results[3]\n",
    "print \"e \", results[4]\n",
    "print \"soft_e\", results[5]\n",
    "print \"reduce_soft_e\", results[6]\n",
    "print \"new\", results[7]\n",
    "print \"pack_2lists_reshaped_back\", results[8]\n",
    "print \"new back\", results[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
