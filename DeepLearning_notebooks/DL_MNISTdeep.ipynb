{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images from MNIST and \n",
    "\n",
    "Maria Leonor Zamora Maass\n",
    "\n",
    "***\n",
    "\n",
    "Image is naturally a 3D tensor: RGB channels + spatial dimension\n",
    "\n",
    "A batch of images amounts to be 4D tensor: [batchSize x nchannels x width x height]\n",
    "\n",
    "Download MNIST training dataset using [torchvision](https://pypi.python.org/pypi/torchvision/0.1.8)\n",
    "\n",
    "\n",
    "Other options: \n",
    "\n",
    "- For images, packages such as Pillow, OpenCV are useful.\n",
    "- For audio, packages such as scipy and librosa\n",
    "- For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #\n",
    "                             ])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, \n",
    "                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Show the size of train set data (just the size, donâ€™t dump them all out..) and Show the size of train set labels\n",
    "\n",
    "Access the first image of MNIST train set (you may use any method to display it, such as matplotlib, where you might\n",
    "need to cast it into numpy)\n",
    "Make a grid of a batch of train set data\n",
    "\n",
    "Declare a DataLoader first, with size 4\n",
    "\n",
    "Use the torchvision.make_grid\n",
    "\n",
    "Verify that the batch of samples are consistent with the batch of labels (by printing is enough)\n",
    "\n",
    "What about a different size of batch, say 32?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print trainset.train_data.size()\n",
    "print trainset.train_labels.size()\n",
    "#trainloader.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5   # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    \n",
    "\n",
    "def imshow_othernorm(img):\n",
    "    img = img / 10 + 0.5   # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6     1     5     0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no4pdRCRj/h9CfL8B9lh2BQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118f55f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# show some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s'%labels[j]for j in range(4)))  # This range is because batch-size is 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4     7     7     5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE/FmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117bf72d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "# print images\n",
    "imshow_othernorm(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s'%labels[j]for j in range(4)))  # This range is because batch-size is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()\n",
    "#1 channel , 4 for the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (MNIST Classification Neural network):\n",
    "\n",
    "***\n",
    "\n",
    "Define a Convolution Neural Network and a Classification Cross-Entropy loss and SGD with momentum 0.9\n",
    "\n",
    "\n",
    "Declare a similar network defined here: http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py and also explained for CIFAR dataset here http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net_lqo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*4*4, 120) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You need to find a way to get it to work on MNIST, which is grayscale and of size 28x28\n",
    "\n",
    "Declare a loss functional using CrossEntropy used for classification\n",
    "\n",
    "Declare an optimizer using ADAM and prepare a batch of samples from MNIST\n",
    "\n",
    "Zeroize the gradient of the network\n",
    "\n",
    "Run forward pass and Print the loss \n",
    "\n",
    "Run backward pass and Print the mean, max and min value of gradient module by module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "torch.Size([10, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) # conv1's .weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()                                 # use a Classification Cross-Entropy loss\n",
    "criterion2 = F.nll_loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)   # Define an optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.396\n",
      "[1,  4000] loss: 0.644\n",
      "[1,  6000] loss: 0.497\n",
      "[1,  8000] loss: 0.431\n",
      "[1, 10000] loss: 0.399\n",
      "[1, 12000] loss: 0.349\n",
      "[1, 14000] loss: 0.340\n",
      "[2,  2000] loss: 0.295\n",
      "[2,  4000] loss: 0.288\n",
      "[2,  6000] loss: 0.277\n",
      "[2,  8000] loss: 0.272\n",
      "[2, 10000] loss: 0.232\n",
      "[2, 12000] loss: 0.256\n",
      "[2, 14000] loss: 0.270\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(2): # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):    # Batch from the trainloader (4 size in this case)\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        #loss = criterion(outputs, labels)\n",
    "        loss = criterion2(outputs, labels)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
